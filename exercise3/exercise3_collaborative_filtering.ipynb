{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Social Computing - Summer 2018\n",
    "# Exercise 3: Collaborative Filtering Recommender System\n",
    "\n",
    "Write a simple collaborative filtering movie recommender in python. The input (attached to this exercise) is a subset of the MovieLens dataset (movielens.org), which contains 1862 movies, and 100K ratings. Find the dataset Piazza. The input is provided in two data files: u.item: is a listing of movies. Each row represents a movie with its attributes separated by ‘|’. We are only interested in the first two attributes which are the movie ID and the movie name. The second data file is u.data, which contains the movie ratings by users. A single row represents one user’s rating for one movie, and the attributes are (from left to right): user ID, movie ID, rating, and timestamp. \n",
    "\n",
    "<b>Exercise</b><br>\n",
    "The entry point to your recommendation engine should be a python method called “recommend” that takes a user ID, and paths to the two aforementioned data files. The method should return the top twenty recommended movies for that user <u><b>(The movies should not have been rated by that user before)</b></u>. The output should be a list of python tuples (sorted by recommended movies' expected ratings: highest first). Each tuple has the following two attributes: movie name, expected rating. You are free to design your recommendation engine the way you want but straightforward collborative filtering is highly recommended. Make sure that the code is clean, readable, and well documented. Test the code for user 15!\n",
    "\n",
    "### The Collaborative Filtering Recommender\n",
    "The idea of collaborative filtering is to find similar users to the target user. The items highly rated by those users are likely to be favorited by the target user. Therefore, the main problem is to find the list of users similar to the target user. There are several ways of measuring similarity. We could e.g. use cosine similarity but one of the simplest measures is Euclidean distance. Your program should calculate the absolute Euclidean distance between the target user and all other users in the dataset and calculate the expected rating for the target user for each movie in the dataset based on the forumla:\n",
    "\n",
    "$$r_{ui} = \\frac{\\sum_{v \\in N_i(u)} w_{uv}r_{vi}}{\\sum_{v \\in N_i(u)} w_{uv}}$$\n",
    "\n",
    "Where $r_{ui}$ is the expected recommendation of item i for target user u. $N_i(u)$ is the set of similar users to target user u for the designated item i. $w_{uv}$ is the similarity score between users u and v (used as a weighting factor) for $r_{vi}$ which is the rating of user v for item i. \n",
    "The curious student should refer to: Ricci et al (eds.) \"Recommender Systems Handbook\", Springer 2011, for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Fire Down Below (1997)', 5), ('Paths of Glory (1957)', 5), ('Empire Strikes Back, The (1980)', 5), ('Princess Bride, The (1987)', 5), ('Alien (1979)', 5), ('Godfather: Part II, The (1974)', 5), ('Graduate, The (1967)', 5), ('Hoodlum (1997)', 5), ('187 (1997)', 5), ('Soul Food (1997)', 5), ('Money Talks (1997)', 5), (\"Eve's Bayou (1997)\", 5), ('North by Northwest (1959)', 5), ('Killing Fields, The (1984)', 4), ('Shine (1996)', 4), ('Hoop Dreams (1994)', 4), ('Apocalypse Now (1979)', 4), ('Quiz Show (1994)', 4), ('Englishman Who Went Up a Hill, But Came Down a Mountain, The (1995)', 4), ('Piano, The (1993)', 4)]\n"
     ]
    }
   ],
   "source": [
    "# Method has following parameters:\n",
    "# path_u_item: path to u.item as a string\n",
    "# HINT: movie_dictionary = {movie_id: movie_name}\n",
    "# TODO Parse u.item\n",
    "def create_movie_dictionary(path_input):\n",
    "    movie_dictionary = {}\n",
    "    for line in open(path_input):\n",
    "        movie_data = line.strip().split('|')\n",
    "        movie_dictionary[int(movie_data[0])] = movie_data[1]  \n",
    "    return movie_dictionary\n",
    "\n",
    "\n",
    "# Create a dictionary: {user_id: {movie_id: user_rating}}\n",
    "def create_user_rating_dictionary(path_input):\n",
    "    user_rating_dictionary = {}\n",
    "    for line in open(path_input):\n",
    "        row = line.strip().split('\\t')\n",
    "        user_id, movie_id, rating, timestamp = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "        try:\n",
    "            user_rating_dictionary.setdefault(user_id, {})\n",
    "            user_rating_dictionary[user_id][movie_id] = rating\n",
    "        except KeyError:\n",
    "            print \"key error found! \" + user_id + \" \" + movie_id\n",
    "    return user_rating_dictionary\n",
    "\n",
    "\n",
    "# Using Euclidean distance to calculate similarity score\n",
    "def calculate_similarity_score(ratings, user_id1, user_id2):\n",
    "    common_movies = []\n",
    "    # TODO Find common movies rated by both users\n",
    "    user1_movies = ratings[user_id1]    \n",
    "    user2_movies = ratings[user_id2]\n",
    "    \n",
    "    for movie in user2_movies:\n",
    "        if movie in user1_movies:\n",
    "            common_movies.append(movie)            \n",
    "            \n",
    "    if len(common_movies) == 0: # no common ratings between two users. Similarity is 0\n",
    "        return 0\n",
    "\n",
    "    # TODO Calculate Euclidean distance between two users based on their common ratings\n",
    "    sum_of_squares_of_differences = 0\n",
    "    for movie_id in common_movies:    \n",
    "        sum_of_squares_of_differences += (user1_movies[movie_id] - user2_movies[movie_id])**2\n",
    "        \n",
    "        # TODO Accumulate the sum of squares of differences in ratings between the two users for the same movie\n",
    "    return 1 / (1 + sum_of_squares_of_differences)   \n",
    "\n",
    "    \n",
    "\n",
    "def cf_recommend(ratings, target_user_id):\n",
    "    weighted_ratings = {} # {movie_id: weighted_rating}\n",
    "    similarity_scores = {} # {movie_id: similarity_score}\n",
    "    recommended_movie_list = [] # Each element is a tuple (estimated_rating, movie_id)\n",
    "    for user_id in ratings:\n",
    "        if user_id != target_user_id:\n",
    "            similarity_score = calculate_similarity_score(ratings, target_user_id, user_id)\n",
    "            if similarity_score > 0:\n",
    "                for movie_id in ratings[user_id]:\n",
    "                    # Movie was not recommended by the target user before\n",
    "                    if movie_id not in ratings[target_user_id]:\n",
    "                        if movie_id not in weighted_ratings:\n",
    "                            weighted_ratings[movie_id] = ratings[user_id][movie_id]*similarity_score\n",
    "                        else:\n",
    "                            weighted_ratings[movie_id] += ratings[user_id][movie_id]*similarity_score\n",
    "                        if movie_id not in similarity_scores:\n",
    "                            similarity_scores[movie_id] = similarity_score\n",
    "                        else:\n",
    "                            similarity_scores[movie_id] += similarity_score\n",
    "                        # TODO Accumulate the weighted rating for that movie\n",
    "                        # The weighted rating of the movie = user_id's rating of that movie * similarity \n",
    "                        # score between that user and the target_user \n",
    "                        # of that user to the target_user\n",
    "                        # TODO Accumulate the similarity scores of all users who rated that movie\n",
    "\n",
    "    for movie_id in weighted_ratings:\n",
    "        estimated_rating = weighted_ratings[movie_id] / similarity_scores[movie_id]\n",
    "        # TODO Weighted_rating/sigma (similarity scores of users who rated that movie)\n",
    "        recommended_movie_list.append((estimated_rating, movie_id))\n",
    "    \n",
    "    # TODO Sort the list\n",
    "    recommended_movie_list.sort(key=lambda sort_attr: sort_attr[0], reverse=True)\n",
    "    return recommended_movie_list\n",
    "# List of recommended movies for user_id from highest to lowest estimated rating\n",
    "    \n",
    "\n",
    "# Testing implementation\n",
    "\n",
    "movie_dict = create_movie_dictionary(\"u.item\")\n",
    "ratings = create_user_rating_dictionary(\"u.data\")\n",
    "recommended_movies = cf_recommend(ratings,15)\n",
    "top_twenty = []\n",
    "\n",
    "\n",
    "for estimated_rating, movie_id in recommended_movies[:20]:    \n",
    "    top_twenty.append((movie_dict[movie_id], estimated_rating))\n",
    "print top_twenty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Least misery strategy for group recommendations aggregation\n",
    "import math\n",
    "def least_misery(social_preds, restaurants, group):   \n",
    "    group_ratings = []\n",
    "    # TODO: implement strategy\n",
    "    for restaurant in restaurants:\n",
    "        agg_rating = 0\n",
    "        for member in social_preds:\n",
    "            agg_rating += social_preds[member][restaurant]\n",
    "        group_ratings.append((restaurant, agg_rating))\n",
    "    group_ratings.sort(key = lambda tup: tup[1], reverse = True) \n",
    "    return group_ratings\n",
    "    return group_rating_dict\n",
    "\n",
    "# Using Euclidean distance to calculate similarity score\n",
    "def calculate_similarity_score(ratings, user_id1, user_id2):\n",
    "    \n",
    "    common_movies = []\n",
    "    # TODO Find common movies rated by both usersu\n",
    "    movies1 = ratings[user_id1].keys()\n",
    "    movies2 = ratings[user_id2].keys()\n",
    "    common_movies = list(movies1 & movies2)\n",
    "            \n",
    "    if len(common_movies) == 0: # no common ratings between two users. Similarity is 0\n",
    "        return 0\n",
    "\n",
    "    # TODO Calculate Euclidean distance between two users based on their common ratings\n",
    "    sum_of_squares_of_differences = 0\n",
    "    for movie_id in common_movies:\n",
    "        # TODO Accumulate the sum of squares of differences in ratings between the two users for the same movie\n",
    "        sum_of_squares_of_differences += (ratings[user_id1][movie_id] - ratings[user_id2][movie_id])**2\n",
    "        sum_of_squares_of_differences = math.sqrt(sum_of_squares_of_differences)\n",
    "        \n",
    "    return 1 / (1 + sum_of_squares_of_differences)\n",
    "    \n",
    "\n",
    "def cf_recommend(target_user_id, restaurants, ratings, avg_ratings):\n",
    "    weighted_ratings = {} # {movie_id: weighted_rating}\n",
    "    similarity_scores = {} # {movie_id: similarity_score}\n",
    "    recommended_movie_list = {} # Each element is a tuple (estimated_rating, movie_id)\n",
    "    for user_id in ratings:\n",
    "        if user_id != target_user_id:\n",
    "            similarity_score = calculate_similarity_score(ratings, target_user_id, user_id)\n",
    "            if similarity_score > 0:\n",
    "                for movie_id in ratings[user_id]:\n",
    "                    # Movie was not recommended by the target user before\n",
    "                    if movie_id not in ratings[target_user_id]:\n",
    "                        try:\n",
    "                            if movie_id in weighted_ratings:\n",
    "                                weighted_ratings[movie_id] += ratings[user_id][movie_id]*similarity_score\n",
    "                                similarity_scores[movie_id] += similarity_score\n",
    "                            else:\n",
    "                                weighted_ratings[movie_id] = ratings[user_id][movie_id]*similarity_score\n",
    "                                similarity_scores[movie_id] = similarity_score\n",
    "                        except KeyError:\n",
    "                            print(\"key error found! \" + str(user_id) + \" \" + str(movie_id))\n",
    "  \n",
    "    for key in weighted_ratings: # TODO for each movie\n",
    "        # TODO Weighted_rating/sigma (similarity scores of users who rated that movie)\n",
    "        estimated_rating = weighted_ratings[key]/similarity_scores[key]\n",
    "        recommended_movie_list[key] = estimated_rating\n",
    "       \n",
    "    for restaurant in restaurants:\n",
    "        if restaurant not in weighted_ratings:\n",
    "            recommended_movie_list[restaurant] = avg_ratings[restaurant]\n",
    "        \n",
    "        \n",
    "    return recommended_movie_list # List of recommended movies for user_id from highest to lowest estimated rating\n",
    "\n",
    "\n",
    "def calculate_base_predictions(participant, restaurants, ratings,average_rating):\n",
    "    #TODO: Reuse your collaborative filtering recommender from exercise 3\n",
    "    return cf_recommend(participant, restaurants, ratings, average_rating)\n",
    "\n",
    "def calculate_social_context_aware_predictions(group, restaurants, base_predicted_ratings,dom_expertise):\n",
    "    #TODO: Apply the formula for the participant for each restaurant\n",
    "    social_preds = {}\n",
    "    for member in group:\n",
    "        for restaurant in restaurants:\n",
    "            if member not in social_preds:\n",
    "                social_preds[member] = {}\n",
    "            dom_sum = 0\n",
    "            dom_base_prod = []\n",
    "            for other_members in group:\n",
    "                if member != other_members:\n",
    "                    dom_sum += dom_expertise[str(member)][str(other_members)]\n",
    "                    dom_base_prod.append(dom_expertise[str(member)][str(other_members)]*base_predicted_ratings[str(other_members)][str(restaurant)])\n",
    "\n",
    "            social_preds[member][restaurant] = (1/dom_sum)*(sum(dom_base_prod))    \n",
    "            \n",
    "    return social_preds # {participant_id: {restaurant_id: social_rating}}\n",
    "\n",
    "def get_restaurants(ratings_path): \n",
    "    #TODO: using the ratings return a list of unique restaurant IDs\n",
    "    restaurants_list = list()\n",
    "    f = open(ratings_path, 'r')\n",
    "    lines = f.readlines()[1:]\n",
    "    for line in lines:    \n",
    "        rating_data = line.strip().split(',')\n",
    "        if rating_data[1] not in restaurants_list:\n",
    "            restaurants_list.append(rating_data[1])\n",
    "    \n",
    "    return restaurants_list\n",
    "\n",
    "\n",
    "def get_participants(ratings_path): \n",
    "    #TODO: using the ratings return a list of unique restaurant IDs\n",
    "    participants = []\n",
    "    f = open(ratings_path, 'r')\n",
    "    lines = f.readlines()[1:]\n",
    "    \n",
    "    for line in lines:\n",
    "        ratings_data = line.split(',')\n",
    "        participants.append(ratings_data[0])        \n",
    "    participants = set(participants)\n",
    "    return participants\n",
    "\n",
    "    \n",
    "def create_rating_dictionary(ratings_path):\n",
    "    ratings = {}\n",
    "    average_rating = {}\n",
    "    num_ratings_per_rest = {}\n",
    "    f = open(ratings_path, 'r')\n",
    "    lines = f.readlines()[1:]\n",
    "    for line in lines:    \n",
    "        data = line.strip().split(',')\n",
    "        if data[0] not in ratings:       \n",
    "            ratings[int(data[0])] = {}\n",
    "        ratings[int(data[0])][data[1]] =  ((float(data[2])/100)+(float(data[3])/100)+(float(data[4])/100)+(float(data[5])/100)+(float(data[6])/100)+(float(data[7])/100))/6        \n",
    "    \n",
    "        if data[1] not in average_rating:\n",
    "            average_rating[data[1]] = []\n",
    "        average_rating[data[1]].append(((float(data[2])/100)+(float(data[3])/100)+(float(data[4])/100)+(float(data[5])/100)+ (float(data[6])/100)+(float(data[7])/100))/6)\n",
    "        \n",
    "    for restaurant in average_rating:        \n",
    "        average_rating[restaurant] = sum(average_rating[restaurant])/len(average_rating[restaurant])\n",
    "    \n",
    "    return ratings,average_rating\n",
    "\n",
    "\n",
    "def domain_expertise_parser(domain_expertise_path):\n",
    "    domain_dict = {}\n",
    "    f = open(domain_expertise_path, 'r')\n",
    "    lines = f.readlines()[1:]\n",
    "    for line in lines:\n",
    "        domain_data = line.split(',')\n",
    "        if domain_data[0] not in domain_dict:\n",
    "            domain_dict[domain_data[0]] = {}\n",
    "        domain_dict[domain_data[0]][domain_data[1]] = float(domain_data[2])/100        \n",
    "    \n",
    "    return domain_dict\n",
    "\n",
    "# Group recommender (Main program)\n",
    "def group_recommender(group, ratings_path, domain_expertise_path):\n",
    "    # Pre-processing:\n",
    "    #-----------------\n",
    "    # TODO: parse ratings.csv (e.g into a dictionary of ratings)\n",
    "    # parse domain_expertise.csv (e.g into the dictionary {from: {to, domain_expertise}})\n",
    "    # restaurants = get_restaurants(ratings) --> from the ratings dictionary, extract the list of restaurant IDs (a list of unique restaurant IDs)\n",
    "    \n",
    "    ratings,average_rating = create_rating_dictionary(ratings_path)\n",
    "    restaurants = get_restaurants(ratings_path)\n",
    "    domain_dict = domain_expertise_parser(domain_expertise_path)\n",
    "    participants = list(get_participants(ratings_path))\n",
    "    # Calculate single user recommendations (predicted ratings):\n",
    "    #-------------------------------------------------------------\n",
    "    # For each participant in the group, calculate the base ratings for each restaurant\n",
    "    # For each participant in the group, calculate the social-context-aware predicted ratings (given the base predicted ratings)\n",
    "    base_preds = {}\n",
    "    for participant in participants:\n",
    "        base_preds[participant] = calculate_base_predictions(participant, restaurants, ratings, average_rating)\n",
    "    # Calculate group recommendations (group predicted ratings) - based on the \"Least Misery\" strategy:\n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    # Given the social-context-aware predicted ratings for each group member, aggregate those ratings \n",
    "    # into group recommendations for each restaurant based on the \"Least Misery\" strategy (sorted by predicted ratings: highest first)\n",
    "    social_preds = {}\n",
    "    social_preds = calculate_social_context_aware_predictions(group, restaurants, base_preds, domain_dict)\n",
    "    group_ratings = least_misery(social_preds, restaurants, group)-\n",
    "    \n",
    "    for i in range(len(group_ratings)):\n",
    "        print(group_ratings[i])\n",
    "\n",
    "\n",
    "# Test (Call your main program to test it with the sample groups from the exercise description above)\n",
    "group_recommender([160, 161, 162], \"ratings.csv\", \"domain_expertise.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
